\documentclass{article}

\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{multirow}

\title{Reflection and Traceability Report on \progname}

\author{\authname}

\date{}

\input{../packages/Comments.tex}
\input{../packages/Common.tex}
\input{../packages/Reflection.tex}

\begin{document}

\maketitle

\plt{Reflection is an important component of getting the full benefits from a
learning experience.  Besides the intrinsic benefits of reflection, this
document will be used to help the TAs grade how well your team responded to
feedback.  Therefore, traceability between Revision 0 and Revision 1 is and
important part of the reflection exercise.  In addition, several CEAB (Canadian
Engineering Accreditation Board) Learning Outcomes (LOs) will be assessed based
on your reflections.}

\section{Changes in Response to Feedback}

\subsection{SRS and Hazard Analysis}

Here is the feedback we received on the SRS and Hazard Analysis documents, and the changes we made in response to that feedback.

\begin{longtable}{| p{0.2\textwidth} | p{0.2\textwidth} | p{0.3\textwidth} | p{0.1\textwidth} |}
    \caption{Feedback and Changes for SRS Documentation} \\
    \hline
    \textbf{Feedback Source} & \textbf{Feedback Item} & \textbf{Response} & \textbf{Issue} \\
    \hline
    \endfirsthead
    \hline
    \textbf{Feedback Source} & \textbf{Feedback Item} & \textbf{Response} & \textbf{Issue} \\
    \hline
    \endhead
    \hline
    \endfoot
    TA Feedback & Formatting and Style & Mention figures in paragraphs and fix title & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/125}{\#125}\\
    \hline
    TA Feedback & What not How(Abstract) & Improve constraints details & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/126}{\#126} \\
    \hline
    TA Feedback & Complete, Correct and Unambiguous & Template explanation & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/124}{\#124}\\
    \hline
    TA Feedback & Traceable Requirements & Fix referencing for section 5.2. & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/123}{\#123} \\
    \hline
    TA Feedback & Document Content & Fix functional requirements. & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/122}{\#122} \\
    \hline
    Peer Review & Project Goals & Goal Statements Inconsistency. & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/55}{\#55} \\
    \hline
    Team Feedback & Document Content & Fix FR and NFR to align with the current scope of project & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/201}{\#201}\\
    \hline
    TA Feedback & Document Content & Fixed Citation & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/202}{\#202}\\
    \hline

\end{longtable}

\subsection{Design and Design Documentation}

Here is the feedback we received on the Design and Design Documentation, and the changes we made in response to that feedback.
\begin{longtable}{| p{0.2\textwidth} | p{0.2\textwidth} | p{0.3\textwidth} | p{0.1\textwidth} |}
\hline
\textbf{Feedback Source} & \textbf{Feedback Item} & \textbf{Response} & \textbf{Issue} \\
\hline
TA Feedback & Document Content & Formalization  & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/191}{\#191} \\
\hline
TA Feedback & Document Content & Input represenation & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/192}{\#192} \\
\hline
TA Feedback & Document Content & Specific Definition of JSON & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/193}{\#193} \\
\hline
TA Feedback & Document Content & HTTP Design & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/194}{\#194} \\
\hline
\end{longtable}

\subsection{VnV Plan and Report}

Here is the feedback we received on the VNV Plan and VNV  Report, and the changes we made in response to that feedback.

\begin{longtable}{| p{0.2\textwidth} | p{0.2\textwidth} | p{0.3\textwidth} | p{0.1\textwidth} |}
    \caption{Feedback and Changes for VNV Plan} \\
    \hline
    \textbf{Feedback Source} & \textbf{Feedback Item} & \textbf{Response} & \textbf{Issue} \\
    \hline
    \endfirsthead
    \hline
    \textbf{Feedback Source} & \textbf{Feedback Item} & \textbf{Response} & \textbf{Issue} \\
    \hline
    \endhead
    \hline
    \endfoot
    TA Feedback & Nondynamic testing used as necessary & Improve Testing & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/196}{\#196} \\
    \hline
    TA Feedback & General Information & Objective mismatching & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/195}{\#195} \\
    \hline
    Team Feedback & System Tests for Functional / Nonfunctional Requirements are specific & Update based on team feedback & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/203}{\#203}\\
    \hline
    Team Feedback & Extras & Change extras based on current scope & \href{https://github.com/RezaJodeiri/CXR-Capstone/issues/204}{\#204}\\
    \hline

\end{longtable}

\section{Challenge Level and Extras}

\subsection{Challenge Level}

\plt{State the challenge level (advanced, general, basic) for your project.  Your challenge level should exactly match what is included in your problem statement.  This should be the challenge level agreed on between you and the course instructor.}

\subsection{Extras}

\plt{Summarize the extras (if any) that were tackled by this project.  Extras
can include usability testing, code walkthroughs, user documentation, formal
proof, GenderMag personas, Design Thinking, etc.  Extras should have already
been approved by the course instructor as included in your problem statement.}

\section{Design Iteration (LO11 (PrototypeIterate))}

\plt{Explain how you arrived at your final design and implementation.  How did
the design evolve from the first version to the final version?} 

\plt{Don't just say what you changed, say why you changed it.  The needs of the
client should be part of the explanation.  For example, if you made changes in
response to usability testing, explain what the testing found and what changes
it led to.}

\section{Design Decisions (LO12)}

\plt{Reflect and justify your design decisions.  How did limitations,
 assumptions, and constraints influence your decisions?  Discuss each of these
 separately.}

\section{Economic Considerations (LO23)}

\plt{Is there a market for your product? What would be involved in marketing your 
product? What is your estimate of the cost to produce a version that you could 
sell?  What would you charge for your product?  How many units would you have to 
sell to make money? If your product isn't something that would be sold, like an 
open source project, how would you go about attracting users?  How many potential 
users currently exist?}

\subsection{Market Demand and Opportunity}
The market for AI-driven medical imaging analysis is growing rapidly due to increasing healthcare digitization and the global shortage of radiologists. The demand for fast, accurate, and cost-effective diagnostic tools makes this product highly viable. Potential users include hospitals, clinics, telemedicine providers, and government healthcare initiatives. Additionally, developing countries with limited access to radiologists represent a significant market where AI-powered solutions could improve diagnostic capabilities.

\subsection{Marketing Strategy}
Marketing would involve direct outreach to hospitals and healthcare providers, showcasing the efficiency and accuracy of the model through clinical trials and case studies. Partnerships with electronic health record (EHR) providers could facilitate integration into existing workflows. Furthermore, regulatory approvals such as FDA or Health Canada certification would enhance credibility. However, our team plans more on leveraging via government healthcare programs and partnerships.

\subsection{Production Cost Estimate}
The cost of production includes:
\begin{itemize}
    \item \textbf{Cloud Services (AWS ECS):} The hosting and management of the backend system will be powered by AWS Elastic Container Service. This service will handle containerized microservices, ensuring scalability. Costs for ECS typically range from x to x dollar per month, depending on traffic, load, and the number of services running.
    \item \textbf{GPU/Server Cost:} To train the AI model efficiently, a dedicated GPU or server instance is required for training and inference tasks. For optimal performance, services like AWS EC2 GPU instances would be suitable, which cost around 3 to 5 dollars per hour, depending on the selected instance type. In our case, using the Mcmaster GPU server, there was no cost for training and inference, but we estimate a cost of 500 to 1,000 dollars per month if we did not have access to the mcmaster GPU server. Note our product is the application not the computer or server it runs on.
    \item \textbf{Cost of API Services:} The integration of ChatGPT for natural language processing tasks, such as generating reports or patient interaction, incurs costs based on the number of API calls. This will vary depending on usage but can be estimated at a few cents per API call, estimating the monthly cost to be the amount of patients divded by 100. 
\end{itemize}


\subsection{Pricing Model}
Since the application is enterprise-focussed, there are two models to compare when pricing the users:
\begin{itemize}
    \item \textbf{Charging for number of licenses:} Each hospital pay a monthly fee for the number of licenses they have purchase. Each license represent a radiologist, and no matter the amount of data a radiologist produce, they will get charged the same as others.
    \begin{itemize}
        \item \textbf{Advantages:} This model generate a predictable cashflow and monthly recurring revenue. In addition, it's very straight-forward, making it easy for hospitals to manage and scale licensing cost.
        \item \textbf{Disadvantages:} Experienced radiologists might have significantly more patients than others users (i.e: doctors in training, resident). This creates huge friction for hospitals to buy licenses for specialists with low expected patient count. Additionally, usage prediction becomes tricky for Lung Vision AI since any license can generate an infinite amount of data in theory.
    \end{itemize}
    
    \item \textbf{Charging for number of patients:} Each hospitals pay a monthly fee for the number of patients they service.
    \begin{itemize}
        \item \textbf{Advantages:} This model encourage a pay-as-you-go mentality, making usage and cost prediction for Lung Vision AI a lot simpler. Additionally, this model is suitable for private clinics where patient growth is not too drastic.
        \item \textbf{Disadvantages:} This pricing model is unfavorable for big hospitals, since forecasting expected patients for a given month is difficult, making costs management unpredictable.
    \end{itemize}
\end{itemize}

To balance long-term user satisfaction, affordability, and profitability, our has decided to go with the \textbf{charging for licenses model}, with an upper limit of how many patient are allowed to be created per license. If doctors would like to service more patients using their current license, a different pricing schema will be applied per user.

\subsection{Break-even Analysis}
The cost the project per month can be broken down as follow:
\begin{longtable}{| p{0.15\textwidth} | p{0.2\textwidth} | p{0.2\textwidth} | p{0.45\textwidth}|}
    \hline
    \textbf{Category} & \textbf{Cost} & \textbf{Cost/Month} & \textbf{Description} \\
    \hline

    \multirow{1}{*}{\parbox{0.15\textwidth}{\textbf{Business\\Operation}}}
    & \textbf{Domain Name} & \$1.23 & Cost associated with purchasing and maintaining the domain name for the application. \\
    \hline 

    \multirow{3}{*}{\textbf{Hosting}} 
    & \textbf{Database} & \$13.00 & NoSQL database (AWS DynamoDB) and blob storage expenses (AWS S3). \\
    \cline{2-4}
    & \textbf{Load Balancing} & \$17.60 & Costs of load balancer (AWS ALB) to ensure high availability and scalability of the application. \\
    \cline{2-4}
    & \textbf{Computing} & \$5.00 & Cloud container running cost (AWS Elastic Container Service). \\
    \cline{2-4}
    & \textbf{Other} & \$33.50 & Any additional variable costs, such as OpenAI usage or additional AWS services (AWS ECR, IAM). \\ 
    \hline
    
    & \textbf{Total Cost} & \$70.33 & \\
    \hline
\end{longtable}

\subsection{Conclusion}
Currently, our database contains roughly 20 radiologists, and 100 active patients. By simple calculations
\begin{itemize}
    \item Cost per patient = 70.33/ 100 = 0.7033 dollars
    \item Cost per license = 70.33/ 20 = 14.066 dollars
\end{itemize}
Assuming that there are no other costs of this project (labour, transportation, etc.) the break price per license will be 14.066 dollars, with a max limit of 5 patient per license. For every new patient doctors would like to serve, an additional 0.7033 dollars per user will be charged.

\section{Reflection on Project Management (LO24)}

\subsection{How Does Your Project Management Compare to Your Development Plan}
\begin{enumerate}
    \item[-] We closely followed our scheduled meeting plan, holding weekly stand-ups and additional ad hoc meetings during key development phases (Rev0, Rev1,Final Demonstration). These meetings helped us stay aligned and adapt quickly when challenges arose. 
    \item[-] Our primary communication tools(Discord and GitHub) were used effectively for both asynchronous updates and collaborative debugging. We maintained clear version control and documentation throughout development. 
    \item[-] Roles and responsibilities as outlined in our development plan were largely adhered to. Each member focused on their assigned modules (e.g., frontend UI, model training, backend integration), and we successfully coordinated via our Git branching workflow and task tracking system (GitHub issues).
    \item[-] We used the technologies originally proposed in our plan, including Python, PyTorch, React JS. The only deviation was adopting a Detection Transformer model(DETR) earlier than planned due to its proven effectiveness in localization tasks during our initial model experimentation. 
\end{enumerate}

\subsection{What Went Well?}
\begin{enumerate}
    \item[-] Discord and GitHub Discussions helped streamline both quick check-ins and in-depth technical discussions. Clear communication reduced misunderstandings and sped up decision-making.
    \item[-] Each member had a clearly defined role (e.g., frontend, model dev, backend), which minimized overlap and improved accountability. Tasks were assigned and tracked using GitHub Issues and Project Boards.
    \item[-] Weekly meetings kept everyone aligned, and sprint planning ensured we had clear short-term goals. Checkpoints during development helped catch issues early.
    \item[-] Our planned technologies (PyTorch, Python, React JS) integrated well with each other. Version control via Github was used effectively for collaboration and rollback when needed.
    \item[-] Independent module development (e.g., AI model, UI, API) allowed parallel progress without bottlenecks. CI/CD setup helped with automated testing and smooth deployment.
    
\end{enumerate}

\subsection{What Went Wrong?}
\begin{enumerate}
    \item[-] Some tasks, particularly around localized disease progression tracking, took significantly longer than expected. This affected sprint timelines and required scope adjustments mid-way.
    \item[-] Our original plan didn’t account for debugging, model tuning iterations, or integration testing delays. This compressed our final testing and documentation phases.
    \item[-] Early-stage code and design decisions weren’t always documented consistently, leading to rework during integration. We improved this mid-project by enforcing clearer commit messages and README updates.
    \item[-] Adopting DETR introduced additional complexity (e.g., custom training routines, evaluation metrics), which required more experimentation and adaptation than anticipated.
\end{enumerate}

\subsection{What Would you Do Differently Next Time?}

\begin{enumerate}
    \item[-] Allocate extra time in the schedule for unexpected delays, model tuning, and integration/debugging.
    \item[-] Build a rough end-to-end prototype early to identify integration pain points sooner, even before full model training is complete.
    \item[-] Maintain consistent documentation practices from the start, including API specs, model details, and configuration notes, to reduce confusion later.
    \item[-] Involve test users (or at least team cross-reviews) earlier in the UI development cycle to catch usability issues before final sprint.
    \item[-] Identify high-risk components (e.g., novel model architectures) up front and create extra plans or fallback options.
\end{enumerate}

\section{Reflection on Capstone}

\plt{This question focuses on what you learned during the course of the capstone project.}

\subsection{Which Courses Were Relevant}

\begin{itemize}
    \item \textbf{4ML3 Machine Learning and AI:} The principles and techniques from this course provided a foundation for understanding how to train and deploy machine learning models, especially the convolutional neural networks (CNNs) used for image classification in medical X-rays. Key topics such as model validation, overfitting, and the use of pre-trained models were directly applicable to the AI model development for disease prediction.
    
    \item \textbf{4HC3 Human Computer Interfaces:} The knowledge gained from this course on Norman’s principles of design was crucial in designing an intuitive and effective user interface for the capstone project. Understanding the user experience was essential for ensuring that the system is accessible and user-friendly, especially for medical professionals who will interact with the system.
    
    \item \textbf{4A03 Ethics:} This course allowed our group to have some former background in the ethical implications of using AI in healthcare, especially regarding privacy, consent, and ensuring that the model works equitably across different patient demographics. This understanding guided the way our team handled data and made design decisions for this project.
    
    \item \textbf{4X03 Scientific Computation:} This course helped the group understand numerical methods and how to implement efficient algorithms for scientific computing. It was particularly useful when optimizing performance for processing large-scale image datasets, such as chest X-rays, and for ensuring that the system was computationally feasible and efficient.

\end{itemize}

\subsection{Knowledge/Skills Outside of Courses}

\begin{itemize}
    \item \textbf{Deep Learning Frameworks (PyTorch):} The team collectively enhanced its understanding of PyTorch, a deep learning framework, to implement the AI model for chest X-ray analysis. This involved collaboratively building convolutional neural networks (CNNs), fine-tuning pre-trained models, and developing robust image data pipelines for preprocessing and augmenting the X-ray images.
        
    \item \textbf{Regulatory Compliance in Healthcare (HIPAA):} Since the project involves medical data and aims to have real-world applications in healthcare, the team researched and gained knowledge about healthcare regulations like Health Insurance Portability and Accountability Act for AI-based medical tools. This included understanding privacy concerns and compliance measures for handling patient data safely and legally. 
        
    \item \textbf{API Integration and Deployment:} To integrate the machine learning model into a production environment, the team learned how to set up RESTful APIs and integrate them with the frontend. This included working with cloud services such as AWS to deploy the system and ensure scalability for real-world use. This was crucial for making the AI model accessible to healthcare professionals and ensuring that it could handle multiple requests simultaneously. 
        
    \item \textbf{Data Annotation and Augmentation for Medical Imaging:} The team acquired knowledge on handling medical image datasets, including proper annotation of X-ray images for training purposes and applying image augmentation techniques to improve model robustness. This was particularly important as public datasets for chest X-rays can be limited and require preprocessing for real-world applications. 
        
    \item \textbf{Performance Monitoring and Model Optimization:} To ensure that the AI system performed well in production, the team explored model optimization techniques, such as hyperparameter tuning, and utilized performance monitoring tools to track the model’s real-world effectiveness in detecting lung diseases. This included setting up logging and feedback mechanisms to ensure continuous learning and improvement.
\end{itemize}

\end{document}