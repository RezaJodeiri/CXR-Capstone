# Author: Reza Jodeiri, Nathan Luong

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: local.Dockerfile
      args:
        - REACT_APP_API_URL=${PROTOCOL}://${HOST}:${BACKEND_HOST_PORT}
    ports:
      - ${FRONTEND_HOST_PORT}:3000
    environment:
      - WATCHPACK_POLLING=true
    command: npm start
    depends_on:
      - backend
    image: neuralanalyzer/frontend:dev
    volumes:
      - ./frontend:/app
      - /app/node_modules

  backend:
    build: ./backend
    ports:
      - ${BACKEND_HOST_PORT}:5000
    environment:
      - FRONTEND_URL=${PROTOCOL}://${HOST}:${FRONTEND_HOST_PORT}
      - NEURALANALYZER_MODEL_URL=${PROTOCOL}://neuralanalyzer_model:${NEURALANALYZER_MODEL_HOST_PORT}
    command: python app.py
    image: neuralanalyzer/backend:latest
    depends_on:
      - neuralanalyzer_model
    volumes:
      - ./backend:/app
    env_file:
      - ./backend/.env
    networks:
      - backend_private_network

  neuralanalyzer_model:
    build: ./ai_services/neuralanalyzer
    ports:
      - 9999:9999
    command: python neural_app.py
    image: neuralanalyzer:latest
    volumes:
      - ./ai_services/neuralanalyzer:/app
    networks:
      - backend_private_network

    #CUDA support
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    #   - NVIDIA_DRIVER_CAPABILITIES=compute,utility

networks:
  backend_private_network:
    driver: bridge
